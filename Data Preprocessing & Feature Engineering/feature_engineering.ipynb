{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### df만 정의해주기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Info gain\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# Assuming df is your dataset dataframe\n",
    "# Specify the target column\n",
    "# Replace 'target_column' with the actual name of your target column\n",
    "target_column = 'cooling_power'\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# If the target variable is categorical, encode it\n",
    "if y.dtypes == 'object' or y.dtypes.name == 'category':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Normalize the feature values to ensure fair computation\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Calculate mutual information (Information Gain)\n",
    "mi_scores = mutual_info_classif(X_scaled, y, random_state=42)\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Information Gain': mi_scores\n",
    "}).sort_values(by='Information Gain', ascending=False)\n",
    "\n",
    "print(\"Information Gain for each feature:\")\n",
    "print(mi_df)\n",
    "\n",
    "# Optional: Select top-k features based on Information Gain\n",
    "k = 5  # Set the number of top features you want to keep\n",
    "top_features = mi_df.head(k)['Feature'].tolist()\n",
    "print(\"Top features:\", top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CFS\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Assuming df is your dataset dataframe\n",
    "# Specify the target column\n",
    "# Replace 'target_column' with the actual name of your target column\n",
    "target_column = 'target_column'\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# If the target variable is categorical, encode it\n",
    "if y.dtypes == 'object' or y.dtypes.name == 'category':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Function to calculate CFS score\n",
    "def cfs_score(features, target):\n",
    "    num_features = len(features.columns)\n",
    "    if num_features == 0:\n",
    "        return 0\n",
    "\n",
    "    correlations = []\n",
    "    # Correlation between each feature and target\n",
    "    for feature in features.columns:\n",
    "        corr = np.corrcoef(features[feature], target)[0, 1]\n",
    "        correlations.append(abs(corr))\n",
    "\n",
    "    feature_corr_sum = sum(correlations)\n",
    "\n",
    "    # Pairwise correlation among features\n",
    "    pairwise_corr_sum = 0\n",
    "    for feature_pair in combinations(features.columns, 2):\n",
    "        pair_corr = np.corrcoef(features[feature_pair[0]], features[feature_pair[1]])[0, 1]\n",
    "        pairwise_corr_sum += abs(pair_corr)\n",
    "\n",
    "    avg_feature_corr = feature_corr_sum / num_features\n",
    "    avg_pairwise_corr = (pairwise_corr_sum / (num_features * (num_features - 1) / 2)) if num_features > 1 else 0\n",
    "\n",
    "    # CFS formula\n",
    "    return avg_feature_corr / np.sqrt(avg_pairwise_corr) if avg_pairwise_corr > 0 else avg_feature_corr\n",
    "\n",
    "# Calculate CFS score for all features\n",
    "cfs_scores = []\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    for feature_subset in combinations(X.columns, i):\n",
    "        subset_df = X[list(feature_subset)]\n",
    "        score = cfs_score(subset_df, y)\n",
    "        cfs_scores.append((feature_subset, score))\n",
    "\n",
    "# Sort subsets by CFS score\n",
    "top_cfs_scores = sorted(cfs_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top subset\n",
    "print(\"Top feature subsets by CFS score:\")\n",
    "for subset, score in top_cfs_scores[:5]:  # Display top 5 subsets\n",
    "    print(f\"Features: {subset}, CFS Score: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSS\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Assuming df is your dataset dataframe\n",
    "# Specify the target column\n",
    "# Replace 'target_column' with the actual name of your target column\n",
    "target_column = 'target_column'\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# If the target variable is categorical, encode it\n",
    "if y.dtypes == 'object' or y.dtypes.name == 'category':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Function to calculate CSS score\n",
    "def css_score(features, target):\n",
    "    feature_subsets = features.values.tolist()\n",
    "    unique_combinations = set(tuple(row) for row in feature_subsets)\n",
    "\n",
    "    # Calculate consistency\n",
    "    consistency = 0\n",
    "    for combination in unique_combinations:\n",
    "        indices = [i for i, row in enumerate(feature_subsets) if tuple(row) == combination]\n",
    "        target_values = target[indices]\n",
    "        most_common = max(np.bincount(target_values))\n",
    "        consistency += most_common\n",
    "\n",
    "    return consistency / len(target)\n",
    "\n",
    "# Calculate CSS score for all feature subsets\n",
    "css_scores = []\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    for feature_subset in combinations(X.columns, i):\n",
    "        subset_df = X[list(feature_subset)]\n",
    "        score = css_score(subset_df, y)\n",
    "        css_scores.append((feature_subset, score))\n",
    "\n",
    "# Sort subsets by CSS score\n",
    "top_css_scores = sorted(css_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top subset\n",
    "print(\"Top feature subsets by CSS score:\")\n",
    "for subset, score in top_css_scores[:5]:  # Display top 5 subsets\n",
    "    print(f\"Features: {subset}, CSS Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
